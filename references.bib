@online{sagov,
    title = "State of the Nation Address",
    url  = "https://www.gov.za/state-nation-address",
    addendum = "(accessed: 16.10.2023)",
    keywords = "President,Parliament"
}

@article{Dufourq2022,
   abstract = {Progress in deep learning, more specifically in using convolutional neural networks (CNNs) for the creation of classification models, has been tremendous in recent years. Within bioacoustics research, there has been a large number of recent studies that use CNNs. Designing CNN architectures from scratch is non-trivial and requires knowledge of machine learning. Furthermore, hyper-parameter tuning associated with CNNs is extremely time consuming and requires expensive hardware. In this paper we assess whether it is possible to build good bioacoustic classifiers by adapting and re-using existing CNNs pre-trained on the ImageNet dataset – instead of designing them from scratch, a strategy known as transfer learning that has proved highly successful in other domains. This study is a first attempt to conduct a large-scale investigation on how transfer learning can be used for passive acoustic monitoring (PAM), to simplify the implementation of CNNs and the design decisions when creating them, and to remove time consuming hyper-parameter tuning phases. We compare 12 modern CNN architectures across 4 passive acoustic datasets that target calls of the Hainan gibbon Nomascus hainanus, the critically endangered black-and-white ruffed lemur Varecia variegata, the vulnerable Thyolo alethe Chamaetylas choloensis, and the Pin-tailed whydah Vidua macroura. We focus our work on data scarcity issues by training PAM binary classification models very small datasets, with as few as 25 verified examples. Our findings reveal that transfer learning can result in up to 82% F1 score while keeping CNN implementation details to a minimum, thus rendering this approach accessible, easier to design, and speeding up further vocalisation annotations to create PAM robust models.},
   author = {Emmanuel Dufourq and Carly Batist and Ruben Foquet and Ian Durbach},
   doi = {10.1016/j.ecoinf.2022.101688},
   issn = {15749541},
   journal = {Ecological Informatics},
   keywords = {Bioacoustics,Convolutional neural networks,Deep learning,Transfer learning,Vocalisation classification},
   month = {9},
   publisher = {Elsevier B.V.},
   title = {Passive acoustic monitoring of animal populations with transfer learning},
   volume = {70},
   year = {2022},
}

@article{chen2020,
	title = {Essential Elements of Natural Language Processing: What the Radiologist Should Know},
	author = {Chen, Po-Hao},
	doi = {https://doi.org/10.1016/j.acra.2019.08.010},
	issn = {1076-6332},
	journal = {Academic Radiology},
	volume = {27},
	issue = {1},
	year = {2020},
	pages = {6--12}
}

@article{craja2020,
	title = {Deep learning for detecting financial statement fraud},
	author = {Craja, Patricia and Kim, Alisa and Lessmann, Stefan},
	journal = {Decision Support Systems},
	volume = {139},
	year = {2020},
	pages = {113421}
}

@article{baena-garcia2011,
	title = {TF-SIDF: Term frequency, sketched inverse document frequency},
	author = {Baena-García, Manuel and Carmona-Cejudo, José M. and Castillo, Gladys and Morales-Bueno, Rafael},
	journal = {2011 11th International Conference on Intelligent Systems Design and Applications},
	publisher = {IEEE},
	pages = {1044--1049},
	year = {2011}
}

@book{tunstall2022,
	title = {Natural language processing with transformers},
	author = {Tunstall, Lewis and Von Werra, Leandro and Wolf, Thomas},
	publisher = {O'Reilly Media Inc.},
	year = {2022}
}

@book{delip2019,
	title = {Natural language processing with PyTorch: build intelligent language applications using deep learning},
	author = {Delip, Rao and McMahan, Brian},
	publisher = {O'Reilly Media Inc.},
	year = {2019}
}

@article{katuwal2018,
	title = {An ensemble of decision trees with random vector functional link networks for multi-class classification},
	author = {Katuwal, Rakesh, and Suganthan,  Ponnuthurai N. and Zhang, Le},
	journal = {Applied Soft Computing},
	volume = {70},
	year = {2018},
	pages = {1146--1153}
}

@article{hastie2009,
	title = {Random forests},
	author = {Hastie, Trevor, and Tibshirani,  Robert and Friedman, Jerome},
	journal = {The Elements of Statistical Learning: Data mining, Inference, and Prediction},
	year = {2009},
	pages = {567--604}
}

@article{liu2017,
	title = {A gradient-boosting decision-tree approach for firm failure prediction: an empirical model evaluation of Chinese listed companies},
	author = {Liu, Jiaming, and Wu, Chong},
	journal = {Journal of Risk Model Validation},
	year = {2017}
}

@article{zhang2015,
	title = {A gradient boosting method to improve travel time prediction},
	author = {Zhang, Yanru and Haghani, Ali},
	journal = {Transportation Research Part C: Emerging Technologies},
	year = {2015},
	pages = {308--324},
	volume = {58}
}

@article{fath2020,
	title = {Implementation of multilayer perceptron (MLP) and radial basis function (RBF) neural networks to predict solution gas-oil ratio of crude oil systems},
	author = {Fath, Aref Hashemi and Madanifar, Farshid and Abbasi, Masood},
	journal = {Petroleum},
	volume = {6},
	issue = {1},
	pages = {80--91},
	year = {2020}
}

@article{bebis1994,
	title = {Feed-forward Neural Networks},
	author = {Bebis, George, and Georgiopoulos, Michael},
	journal = {Ieee Potentials},
	volume = {13},
	issue = {4},
	pages = {27--31},
	year = {1994}
}

@article{despotovic2017,
	title = {Sentiment analysis of microblogs using multilayer feed-forward artificial neural networks},
	author = {Despotovic, Vladimir and Tanikic, Dejan},
	journal = {Computing and Informatics},
	volume = {36},
	issue = {5},
	pages = {1127--1142},
	year = {2017}
}

@article{oyewola2023,
	title = {Optimizing sentiment analysis of Nigerian 2023 presidential election using two-stage residual long short term memory},
	author = {Oyewola, David Opeoluwa, Oladimeji, Lawal Abdullahi and Julius, Sowore Olatunji and Kachalla, Lummo Bala and Dada, Emmanuel Gbenga},
	doi = {https://doi.org/10.1016/j.heliyon.2023.e14836},
	journal = {Heliyon},
	volume = {9},
	issue = {4},
	pages = {1--24},
	year = {2023}
}

@book{tomar2023,
	title = {Communication, Networks and Computing: Third International Conference, CNC 2022, Gwalior, India, December 8–10, 2022, Proceedings, Part I},
	author = {Tomar, Ranjeet Singh and Verma, Shekhar and Chaurasia, Brijesh Kumar and Singh, Vrijendra and Abawajy, Jemal H. and Akashe, Shyam and Hsiung, Pao-Ann and Prasad, Ramjee},
	publisher = {Springer Nature},
	year = {2023}
}

@article{demata2022,
	title = {Biomedical Multimodal Explanations-Increasing Diversity and Complementarity in Explainable Artificial Intelligence},
	author = {da Mata, Diogo Baptista Martins},
	year = {2022}
}

@article{grm2018,
	title = {Strengths and weaknesses of deep learning models for face recognition against image degradations},
	author = {Grm, Klemen, Štruc, Vitomir and Artiges, Anais and Caron, Matthieu and Ekenel, Hazım K.},
	journal = {Iet Biometrics},
	volume = {7},
	issue = {1},
	pages = {81--89},
	year = {2018}
}

@article{akhtar2020,
	title = {Interpretation of intelligence in CNN-pooling processes: a methodological survey},
	author = {Akhtar, Nadeem, and Ragavendran, U.},
	journal = {Neural computing and applications},
	volume = {32},
	issue = {3},
	year = {2020},
	pages = {879--898}
}

@article{mathieu2015,
	title = {Deep Multi-Scale Video Prediction Beyond Mean Square Error},
	author = {Mathieu, Michael and Couprie, Camille and LeCun Yann},
	journal = {arXiv preprint arXiv:1511.05440},
	year = {2015}
}

@book{james2017,
	title = {An Introduction to Statistical Learning: With Applications in R},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and Taylor, Jonathan},
	publisher = {Springer},
	year = {2017},
	edition = {8}
}

@article{ganganwar2012,
	title = {An overview of classification algorithms for imbalanced datasets},
	author = {Ganganwar, Vaishali},
	journal = {International Journal of Emerging Technology and Advanced Engineering},
	volume = {2},
	issue = {4},
	year = {2012}
}