knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 1/ds4l-assignment-1/")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
# Clear global environment
rm(list=ls())
# Libraries we need
libs <- c('dplyr', 'ggplot2', 'lubridate', 'keras', 'quarto', 'readr', 'stringr', 'tidytext', 'tfhub')
# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
install.packages(libs[!installed_libs], repos='http://cran.us.r-project.org')
}
# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
use_virtualenv("myenv", required = TRUE)
??dtm
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 1/ds4l-assignment-1/")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
# Clear global environment
rm(list=ls())
# Libraries we need
libs <- c('dplyr', 'ggplot2', 'lubridate', 'keras', 'tm', 'quarto', 'readr', 'stringr', 'tidytext', 'tfhub')
# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
install.packages(libs[!installed_libs], repos='http://cran.us.r-project.org')
}
# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
use_virtualenv("myenv", required = TRUE)
unzip("sona-addresses-1994-2023.zip", exdir = "data")
# Get a list of all text files in the directory
text_files <- list.files(path = "data", pattern = ".txt")
# Initialize an empty list to store the data
speech_data <- c()
i = 0
num_chars <- c(27050, 12786, 39019, 39524, 37489, 45247, 34674, 41225, 37552, 41719, 50544, 58284, 34590, 39232, 54635, 48643, 48641, 44907, 31101, 47157, 26384, 33281, 33376, 36006, 29403, 36233, 32860, 32464, 35981, 33290, 42112, 56960, 47910, 43352, 52972, 60000)
# Loop through the list of text files and read them into R
for (file in text_files) {
i = i + 1
# speech <- readLines(file, warn = FALSE)
# Open the file for reading
file_handle <- file(paste("data/", file, sep = ""), "r")
speech <- readChar(file_handle, nchars = 60000)
# speech_data[[file]] <- speech
speech_data[i] <- speech
# Close the file
close(file_handle)
}
sona <- data.frame(filename = text_files, speech = speech_data, stringsAsFactors = FALSE)
# extract year and president for each speech
sona$year <- str_sub(sona$filename, start = 1, end = 4)
sona$president <- str_remove_all(str_extract(sona$filename, "[dA-Z].*\\."), "\\.")
# clean the sona dataset by adding the date and removing unnecessary text
replace_reg <- '(http.*?(\\s|.$))|(www.*?(\\s|.$))|&amp;|&lt;|&gt;|\n'
sona <-sona %>%
mutate(speech = str_replace_all(speech, replace_reg , ' ')
,date = str_sub(speech, start=1, end=30)
,date = str_replace_all(date, "February", "02")
,date = str_replace_all(date, "June", "06")
,date = str_replace_all(date, "Feb", "02")
,date = str_replace_all(date, "May", "05")
,date = str_replace_all(date, "Jun", "06")
,date = str_replace_all(date, "Thursday, ","")
,date = str_replace_all(date, ' ', '-')
,date = str_replace_all(date, "[A-z]",'')
,date = str_replace_all(date, '-----', '')
,date = str_replace_all(date, '----', '')
,date = str_replace_all(date, '---', '')
,date = str_replace_all(date, '--', '')
)
sona$date[36] <- "09-02-2023"
sona$year[36] <- "2023"
sona$date <- dmy(sona$date)
sona <- sona %>%
select(date, speech, year, president)
sona_target <- as.integer(factor(sona$president)) - 1
unnest_reg <- "[^A-Za-z_\\d#@']"
words_to_remove <- c("government", "South Africa", "national",
"country", "south", "africa", "honourable",
"people")
# sona_speeches <-
speech_tokens <- sona %>%
unnest_tokens(word, speech, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words)# %>%
# filter(!word %in% words_to_remove)
#speech_tokens <- speech_tokens %>%
#  filter(!word %in% words_to_remove)
load("dsfi-lexicons.Rdata")
sona_target
